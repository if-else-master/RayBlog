[{"title":"2020 全國技能競賽網頁設計","url":"/RayBlog/2020/10/15/2020%E5%85%A8%E5%9C%8B%E6%8A%80%E8%83%BD%E7%AB%B6%E8%B3%BD%E7%B6%B2%E9%A0%81%E8%A8%AD%E8%A8%88/","content":"2020 全國技能競賽網頁設計參賽心得\n  🥉 榮獲銅牌\n\n\n📋 前言這是我第一次參加全國性的程式競賽。比賽內容要求在四個小時內完成一個完整的網頁前端與後端設計，前端部分使用 HTML、CSS 與 JavaScript，後端則利用 PHP 串接 MySQL 資料庫。主辦方同時提供 phpMyAdmin 作為管理與操作資料庫的工具，讓參賽者能順利完成系統整合。\n\n限時四小時完成前後端整合網頁設計\n前端採用 HTML、CSS 與 JavaScript 技術\n後端使用 PHP 與 MySQL，並透過 phpMyAdmin 管理資料庫\n\n\n\n關於比賽技能競賽是一種展示專業技能與創造力的平台，參賽者通常是各領域的專業人士、學生或技術愛好者。他們通過比賽展現自己的技術能力，並在與其他選手的交流中提升自我。\n這些競賽涵蓋範圍廣泛，從程式設計、機器人設計到烘焙、木工等實用技術領域，都有專屬的賽事設計。參賽者需要在有限的時間內完成高水準的作品或解決特定的挑戰，過程不僅考驗專業知識，還需要創造性思維與臨場應變能力。\n評審通常由該領域的專家組成，根據創意性、實用性和完成度進行綜合評分。技能競賽的目的是促進專業技能的交流與進步，激勵參賽者追求卓越，並為社會培養更多具備實際技能的人才。\n\n準備過程我跟著新北高工的學長姊一起練習，但我在這之前沒有學習過有關網頁技術的任何技能，是以一個小白參加這個比賽。而新北高工的老師從 HTML 和 CSS 的刻板開始教起，實際上在區賽結束以前我都還沒有學習過真正的程式語言。\n而我之所以能順利通過區賽，是因為學長幫我解完了題目，而我將程式碼背下來。\n通過區賽後我要開始準備全國賽，這時候我才學習到 JavaScript 表單驗證、動態內容更新和動畫效果，PHP、SQL 等後端的技術。題目中有考到基本的網頁安全、防止 SQL 注入、權限驗證等。\n而這些大致是我的第一次技能競賽的準備過程。區賽後我深入了解了網頁的運作原理，對於後端的知識也更加好奇。\n\n初賽區賽的地點是在桃園幼獅，正式題目跟公告的題目差不多，不同的地方是資料庫的部分多了修改留言跟刪除留言，其餘的大致一樣。\n我當時是使用 Adobe Dreamweaver 排版，VScode 寫 PHP，但因為不熟練以及很多東西忘記，像是忘記 PHP 的後端連接、忘記 SQL 語法、忘記 XAMPP 的設定等等，總之就是一團糟。\n最後我只完成了首頁跟登入系統，而且登入系統還是寫死的那種，如下：\n$username = &#x27;admin&#x27;;$password = &#x27;1234&#x27;;if ($username == &#x27;admin&#x27; &amp;&amp; $password == &#x27;1234&#x27;) &#123;  echo &quot;登入成功&quot;;&#125; else &#123;  echo &quot;登入失敗&quot;;&#125;\n\n\n決賽決賽地點在台北南港展覽館。當時因疫情需要消毒和戴口罩，雖然稍有不便，但並未影響比賽心情。決賽的題目新增了LOGO設計和網頁開發流程圖，這些在比賽前已經熟練練習，算是必得的分數。此外，正式題目還包括資安相關內容，如預防 SQL 注入、權限失效等，這些也是學長提前提醒並練習過的。 全國賽與區賽最大的不同在於比賽場地為開放空間，像展覽一樣，參觀者可以觀看我們的比賽，這讓壓力增加不少。比賽分兩天，第一天熟悉環境，第二天正式比賽，時間為四小時。 這次準備充分，自信滿滿。我注意到區賽時忽略的細節，例如比賽提供的題目本，其中有重要提示和評分指標。我在前 30 分鐘完成了 LOGO 和網頁開發流程圖後，直接著手分數最高的項目：資料庫 SQL、登入登出、註冊、新增留言、修改留言、刪除留言及顯示留言。由於需要模板支持這些功能，我先用 HTML 製作簡易網站，完成核心功能後再進行 CSS 優化。 相比區賽，我在全國賽的表現進步許多，但仍有遺憾：在後台與資料庫的部分花費太多時間（BUG過多），最後調整策略，先完成CSS和其他有把握的內容。修改留言功能最終未完成，留下些許缺憾。\n\n比賽心得從比賽報名到全國賽得獎只有經過短短四個月，而在這四個月中我學習到了程式語言的邏輯、網頁運作的原理、資料庫的運用、資訊安全等。而這也是我第一次參加如此大型的比賽，在南港展覽館走路都會被採訪，但其實專注在比賽的內容後就不會被外界干擾了。這是一次有趣的經驗，這次的比賽成為我人生的轉折點，為未來的生涯規劃奠定了基礎。\n","tags":["技能競賽","網頁技術","銅牌","比賽"]},{"title":"2021 全國技能競賽商務軟體設計","url":"/RayBlog/2021/11/05/2021%E5%85%A8%E5%9C%8B%E6%8A%80%E8%83%BD%E7%AB%B6%E8%B3%BD%E5%95%86%E5%8B%99%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88/","content":"2021 全國技能競賽商務軟體設計\n  🥈 榮獲銀牌\n\n\n📋 前言這次的比賽內容以 C# 為主要開發語言，著重在邏輯思維的考驗與 Windows Form 應用程式的設計實作。比賽中，我們需運用 ADO.NET 技術連接資料庫，並結合 C# 的各種函式庫功能，完成指定的應用系統開發任務。\n\n以 C# 為核心，考驗程式邏輯與應用能力\n使用 Windows Form 設計桌面應用介面\n透過 ADO.NET 技術實作資料庫連接與操作\n\n\n\n\n關於比賽技能競賽是一種展示專業技能與創造力的平台，參賽者通常是各領域的專業人士、學生或技術愛好者。他們通過比賽展現自己的技術能力，並在與其他選手的交流中提升自我。這些競賽涵蓋範圍廣泛，從程式設計、機器人設計到烘焙、木工等實用技術領域，都有專屬的賽事設計。 參賽者需要在有限的時間內完成高水準的作品或解決特定的挑戰，過程不僅考驗專業知識，還需要創造性思維與臨場應變能力。評審通常由該領域的專家組成，根據創意性、實用性和完成度進行綜合評分。技能競賽的目的是促進專業技能的交流與進步，激勵參賽者追求卓越，並為社會培養更多具備實際技能的人才。\n準備過程在2020年我奪得網頁技術銅牌後，我想要繼續學習程式相關的技能，因此我報名了51屆全國技能競賽商務軟體設計。有了去年的準備經驗，我在學習新東西的時候顯得更加從容。商務軟體設計是使用C#為主體的比賽，是以題目的方式進行，一共公告八題比賽時評審會挑其中四題來比賽。依據往年公告的正式題目，一共會有兩題邏輯題和兩題windows forms題， 而我將從這個方向準備起。C#是物件導向的程式語言，我先是學習了何謂＂物件導向＂？物件導向程式設計（Object Oriented Programming）是一種程式設計方法論，它將軟體系統中的事物（稱為物件）視為具有狀態和行為的實體，並將它們組織成一個相互作用的系統。 這種程式設計方法著重於封裝、繼承和多型等概念，使得程式碼可以更加模組化、易於維護和擴展。 了解完C#基本的知識後，我開始學習遞迴、演算法，氣泡排序法、快速排序法、插入排序法等。總之學習了往年題目前兩題的所有知識。處理完邏輯題後我開使學習windows forms，簡單來說就是把邏輯題套個GUI在結合資料庫做實際的商業運用，我主要學習的點是資料庫ADO.NET連接還有EXCEL的資料處理，這個環節學習到了資料處裡和實際的商業產品製作。而在學習完成後， 我們舉行了一次模擬賽，在這一次的模擬賽中我發現了我deBUG能力的不足，那這個跟程式經驗少和練習的不夠多有關，因此我去解了前幾屆技能競賽的題目增加解題經驗，也在放學後回家多加練習。\n初賽這次的區賽是在萬能科技大學舉行，感恩去年相比，這次我更有信心。區賽的題目大部分都是邏輯題，題目很像APCS實作題，只是規定只能使用C#。我自己的感覺是前三題如果全對可以拿到3級分，第四題是簡單的演算法，第一題是用遞回找最大公因數，第二題賓果遊戲，這題是使用者會先輸入5x5的數字，而電腦會隨機輸出5x5數字直到3條連線才停下來，但因為實在是很難測試，所以在比賽時改成3x3，第四題是快速排序法。最終的成績是區賽銀牌。\n\n決賽決賽的地點原本在高雄科工館，但因為疫情的關西改在萬能科技大學舉行。決賽分為兩天舉行第一天是熟悉場地但不能進入考場。第二天上午評審選了兩題後就開始比賽，第一題是建立與轉換JSON，題目要求將List轉JSON或轉XML要求能隨意轉換，跟公告的題目有點不一樣，正式題目要求我們使用Windows Form 製作，但熟悉此函示庫後就非常容易了。第二題是倒數計時器，一樣改用windows Form做題，簡單的time-1的題目。上午的比賽結束後我們簡單的吃了個午飯就繼續下午的比賽，到了下午我們被告知評審決定更改比賽規則，改為搶分制，前半小時繳交者+50分，第二個半小時後繳交+45分，第三個半小時繳交+10分，第四個半小時繳交者不加分。下午的第一題是車票訂購管理系統第二題是寫入Excel檔案，第一題是ADO.NET的資路庫題，第二題則是考函式庫的使用。因為新規則的關西，題目全對者不一定是第一名，所以我改變了思路，我先把分數較高且能快速做完的第二題做完，然後第一題只做了資料庫連接和顯示資料，因為我有自信我早上的題目全對所以我在比賽開始後47分鐘交卷。最後我的成績是330+45，榮獲銀牌。\n\n比賽心得這次的比賽讓我學習到了演算法和函式庫這些程式語言的骨架，並對其有所應用，相比於去年第一次比賽這次我準備了半年的時間。決賽下午的比賽中評審臨時改比賽規則，但我沒有因此感到慌張，我快速修改解題策略，並最終取得銀牌的好成績。\n","tags":["技能競賽","比賽","商務軟體設計","銀牌"]},{"title":"3R 科技教育文化藝術創作-交通安全組","url":"/RayBlog/2023/10/01/3R%20%E7%A7%91%E6%8A%80%E6%95%99%E8%82%B2%E6%96%87%E5%8C%96%E8%97%9D%E8%A1%93%E5%89%B5%E4%BD%9C-%E4%BA%A4%E9%80%9A%E5%AE%89%E5%85%A8%E7%B5%84/","content":"3R 科技教育文化藝術創作-交通安全組\n    榮獲特優\n\n\n📋 前言這是一個3R比賽是以交通安全為主題，我們這組想要透過VR遊戲的方式來讓大家重視到交通安全的課題，我在這次比賽的工作室建模、製作VR場景以及編寫遊玩的方式。我利用 blender 建置遊戲中的角色，使用 Unity 和 MAKAR 建置遊戲場景以及編寫遊戲的邏輯。最後我們製作出以導盲犬出車禍為主題的多結局VR遊戲，玩家可以在遊玩的過程選擇不同的對話或決定，而這些對話跟決定都會影響著劇情以及結局的走向。我的夥伴是設計故事內容的，總共有三種結局，分別是到盲犬出車禍、導盲犬和盲人小女孩出車禍、以及大家都平安過馬路。\n\n\n關於比賽因應全球化數位學習新趨勢，這個比賽透過競賽激發師生的建構力、創造力與表達力，加強數位內容科技創建能力，同時結合行動學習與跨域學習，鼓勵學生以科技創作融合藝術文化及交通安全議題，展現創新藝文能力，提升多元智慧應用及交通安全素養。在這個比賽的交通安全組規定使用VR AR XR等虛擬實境技術來表達交通安全相關的內容。\n\n準備過程我們參加的是交通安全組，那其實這個主題很多人做過了，不外乎就是用各種方式宣導交通安全。那在我們苦惱怎麼呈現交通安全時，我們參加了一個設計思考的工作坊，主要是教我們怎麼利用設計思考工具來解決生活中的問題，聽講的時候台上的講師說了這麼一段話 ：“對於孩童，我們應該以遊戲的方式教導他們知識”。那這句話給了我靈感，我決定做一個故事書模式的多結局遊戲，有點像一款遊戲叫做：“底特律：變人”，那有了目標之後我們就開始製作。之所以選擇孩童作為目標群眾是因為，孩童普遍不知道車禍的危險，我們想透過多結局的方式帶領孩童們理解車禍以及不遵守交通安全的嚴重性。\n我在團隊中的工作是blender建模、遊戲邏輯書寫，我採用Unity和MAKAR同步進行，Unity製作動畫的邏輯，MAKAR則是設計使用者操作的邏輯。那由於這是我第一次設計VR相關的專案，所以在初期的建模和程式的摸索花了很長的時間。那我也跟我們組的畫師交流了很多次，因為對於blender建模我也是第一次接觸，我需要把畫師的平面圖片成3D圖，這對當時的我來說無疑是一個巨大的挑戰。那在比賽前我們也是順利的將作品做出來了。\n\n比賽過程比賽過程中出了些意外，評審不願意佩戴VR頭盔，導致我們原本的體驗部分無法呈現。但我們有準備第二方案，就是自己佩戴頭盔並將畫面投影到筆電上給評審觀看，這個效果比我們預期的還要好。我們主要介紹了提案的構想、故事內容、呈現方式、與其他交通安全影片的不同，以及技術上的實現。\n故事組編寫了一篇關於盲人女孩與導盲犬遇見卡車司機的故事。在這個故事中，玩家可以選擇扮演柯基、小女孩或卡車司機。如果選擇扮演柯基或小女孩，故事會呈現柯基被卡車撞死而小女孩幸存的情節；若選擇扮演卡車司機，則會有最多兩次選擇機會。第一次選擇是是否開車喝酒，若選擇喝酒，小女孩和柯基都會死；若選擇不喝酒，則會面臨是否闖紅燈的選擇。如果選擇闖紅燈，柯基會死；若選擇不闖紅燈，大家將平安無事。\n我們還設計了一個細節，當玩家選擇錯誤選項並造成悲劇時，會有一位時間之神出現，詢問玩家是否要回到過去改變決定。如果玩家選擇回到過去，遊戲將回到「是否喝酒」的選擇題。\n劇情部分我覺得我們設計得非常好，最後也順利完成，並且在比賽後獲得特優。在頒獎時，一位交通安全NGO組織的理事長（也是評審）對我們的作品很感興趣，並希望我們能授權給他們使用。我們也很高興作品能受到肯定，因此同意了他們的授權請求。\n\n比賽心得這是我第一次製作許虛擬實境相關的專案，對我來說是一次新奇的體驗，尤其是使用 blender 的那種感覺，剛開始覺得很詭異，但收悉軟體的邏輯之後就變得得心應手。同時這個比賽也是一個跨域的內容，我們團隊中融合了語文、美術、資訊等人才，是一次很棒的跨域協作經驗。對於最後評審邀請我們將作品授權給他們我覺得是一件比得獎更讓人興奮的一件事，代表我的作品有機會在更大的舞台展現。總之這是個超級好玩的比賽，學到了很多新東西。\n\n","tags":["比賽","ARVR","虛擬實境","社會議題"]},{"title":"2025 IEYI 世界青少年發明展：臺灣選拔賽","url":"/RayBlog/2025/05/05/2025IEYI%E4%B8%96%E7%95%8C%E9%9D%92%E5%B0%91%E5%B9%B4%E7%99%BC%E6%98%8E%E5%B1%95/","content":"2025 IEYI 世界青少年發明展：臺灣選拔賽\n  🏅 榮獲金牌\n\n\n📋 前言世界青少年發明展（IEYI）鼓勵青少年透過動手實作與創客精神，結合 STEM 教育進行創新發明。我們此次參賽主題與先前兩岸交流相同，聚焦於改善電梯乘坐體驗。本次計畫將優化設計，改用步進馬達線性直線滑軌取代懸吊方式，以提升穩定性，並將樓層數由五層減為三層，以利設計與改進。\n\n\n\n關於比賽世界青少年發明展（International Exhibition for Young Inventor, IEYI）由日本發明協會（JIII）於 2004 年發起，旨在培養青少年的創造力與創新能力。作為創始會員國之一，臺灣可直接以「臺灣」名義參與國際交流，展現優秀的發明成果。\nIEYI 強調動手實作（hands-on）與創客（Maker）精神，並結合 STEM 教育，鼓勵學生將科學、技術、工程與數學融入發明過程。透過發現問題、解決問題與持續改進的歷程，培養青少年的想像力與問題解決能力。\n與此同時，美國「No Child Left Behind」教育政策針對不同學習型態的學生提供適性教學，讓觸覺型學習者透過實作活化知識習得。臺灣教育部與各地教育單位近年來亦積極推動「自學、自造」的創客教育，使學生在實作中學習與創新。\nIEYI 由各會員國輪流舉辦，提供青少年國際交流的機會，拓展全球視野。臺灣代表隊表現優異，經常在國際賽事中獲獎，展現豐富的創意與創新能力。\n發想過程我們這次的主題跟之前去[兩岸交流]的主題是一樣的，都是改善電梯的乘坐體驗，而因為這次時間充裕，所以我們的目標是將作品做得更完整。並從中找到更多可以改善的地方。\n我們這次不打算繼續使用步進馬達懸吊電梯艙的方式，我們使用了步進馬達線性直線滑軌，使用這個零件可以增加我們作品的穩定性，並將原先五層樓的電梯修改為三層樓，方便我們進行設計。\n那這樣我們新的一輪創作就準備開始了。\n製作過程我們先進行了分工，我負責電路設計、焊接、影像辨識等，我的隊友一負責電梯的運行邏輯、作品說明書，我的隊友二負責電梯外觀的雷切設計以及影像辨識。那其實我在這邊還扮演了多工能工具的角色，哪裡需要我幫忙我去哪裡，這是我在嘗試的一種合作模式。\n我們使用樹莓派4 作為驅動電梯的電腦，在測試樹莓派可以透過步進馬達驅動板控制線性直線滑軌滑後，我們就開始著手設計電路、運行邏輯以及外觀。\n在設計時我們遇到了電源供應不足的問題，樹莓派的 5V 無法提供馬達線性直線滑軌足夠的驅動電量，因此需要外接電源。我們使用了 PD誘騙器讓 5V 的充電頭能輸出 12V 的電壓，藉此解決了電壓不足的問題。\n我這邊的電路設計好後我去幫忙了負責設計電梯外觀的隊友，他問說我們電梯的大小以及空間佈局，我使用了厚紙板設計了初始的外型，那討論過後決定設計一個電腦主機外型的電梯造型。\n處理完這些初始問題後我開始開發影像辨識人數的環節，我最初打算使用 YOLO5 nano 計算電梯艙內的人數，但 YOLO 只能辨識人數無法辨識電梯內的空間，這導致了一些非人的物品佔用了電梯的空間卻不會被計算到，所以我決定使用最初設計的方法，用 OpenCV 辨識顏色的能力計算電梯內還剩多少空間。在解決一些版本問題後大致就完成了。\n那接下我們遇到電梯邏輯的問題，這個問題困擾了我們兩個月之久，在比賽前一週都還沒解決，後來我們詳細研究了電梯的研究邏輯，一般來說電梯會有 2~3 片晶片，一片用來控制電梯的馬達、一片用來紀錄樓層的請求、一片用來跟不同的電梯進行溝通。而在我們的電梯中只有一台樹莓派，我們有想過加一顆 D1 或 ESP32，但後來考慮到供電問題，最後我們沒有採用這個方法。經過跟老師的討論，我們想到了可以讓程式碼運行的時候反覆確認有沒有樓層請求\n邏輯如下：\n有人按三樓 -&gt; 電梯開始運行 -&gt; 經過一秒 -&gt; 確認有沒在外部請求電梯 -&gt; 馬達運行 -&gt; 確認有沒在外部請求電梯\n那經過這樣的反覆執行應該就可以解決我們遇到的電梯邏輯問題，但我們沒有考慮到這樣步進馬達會停下來一秒進行判斷，所以從外人的眼光看會覺得這台電梯很卡。而這時候已經到了比賽前一週，經過比賽討論，我們決定改變比賽策略，在仔細研讀過簡章後，我們發現 IEYI 發明展很在意創意以及設計思考等設計師的思考邏輯，所以我決定利用 Python 製作一個智能電梯模擬系統，模擬真正電梯在運行時的邏輯以及外觀，因為模擬軟體缺少了馬達這個物理因素，所以可以無視馬達等一秒的規則。就這樣在帶著不完整的作品，我們前往了比賽會場。\n再次發想在進到比賽現場的環節前我想要補充一下，在我們設計電梯時的閒聊中，我們聊到：在高樓層的如果突然發生意外需要快速到一樓或者醫護人員需要快速到達該樓層時我們該怎麼辦？而這次的閒聊讓我們發現一個淺在的需求，我們決定在電梯上多設計一個警急按鈕，當有人按下時代表情況警急，電梯會立刻將乘客送至一樓，或是將醫護人員送至患者的樓層。那我們有考量到可能會有人亂按，但我們不想要因為這樣而去增加警急按鈕上的防護措施，我們希望遇到緊急狀況住戶或使用者可以快速的按下，所以我們設計了警報器，按下後會發出巨大的警報聲，讓其他人得知電梯內有警急情況，那如果有人亂按當人會受到相應的處罰。\n比賽現場這邊想要先分享一件有趣的事，我們去會場前我們先回學校去拿我們的作品，而拿到作品後我們用手機叫了計程車，當計程車到達師大的時候，計程車司機直接停在大門口，我們下車時氣場十足，我想這無意間增加了我們這組的氣勢。\n比賽開始前我們這組就出現了意外，因為比賽前一天我們的馬達滑軌還沒有固定，所以我索性直接用熱溶膠黏，而我忘記了步進馬達待機時會發熱，所以當我們測試完基本的電梯可以運作後馬達也剛好把熱溶膠融掉了，馬達就這樣應聲倒下，當時我們嚇爛，警急檢查所有線路以及馬達的狀況，幸好事沒有造成什麼毀滅性的破壞，最後我們用電火布將馬達滑軌固定。\n現場我們將平板當作是電梯艙的地板，鏡頭朝向平板並連接我設計的「智能電梯模擬系統」\n因為是第一次比 IEYI 發明展，不清楚評審的問答方式，總共會有 4 個評審，創意性、市場效益性、操作作動性，分別會在不同時間的出現，每個評審有 2min 的報告＋問答，最後一個評審是隨機的，因為一開始不知道這些，在第一個評審出現的時候我們沒有意識到他是創意評審，所以我們按照流程介紹了一遍，而介紹完後還有 30sec 但評審沒有提出任何問題。\n從第二個評審開始我們就有針對評審的審評類別出著重介紹，像是市場效益我們就著重強調了雖然警急按鈕在平時用不到，但不幸用到時會很慶幸有這顆按鈕。操作作動性的部分我們強調了我們電梯的自動畫判斷。最後一個評審因為不知道是評什麼的，所以我們都介紹了一遍。\n那在解說的過程我們發現評審都沒有問題想問我們，這讓我們很緊張，覺得評審對我們的主題沒有興趣。\n比賽心得這次的比賽我們這組「智能電梯」獲得金牌，如果要用一句話形容這次的比賽那一定是：「過程刺激結果意外」為什麼結果會意外呢？那是因為前面有提到我們的電梯邏輯沒有設計好，導致我們的作品運作過程無法使用成品展示，因此我們設計了「智能電梯模擬系統」並將步進馬達設計成可以上下移動但沒有任何邏輯。因此在注重設計跟創客精神的 IEYI 發明展感覺非常的不利。\n在我們報告的同時我有在觀察每一個評審的表情變化，當我提到警急按鈕的功能以及我們設計思考的方式時，我有注意到評審的表情比較認真，所以我推斷這是評審喜歡的點，後續三個評審我都有加重警急按鈕介紹的比例，也許這有幫助我們多加分吧。\n回到學校後我們開了一次復盤會議，大致是討論：我們哪裡做得很好以及評審為什麼沒有問問題，明明還有時間？那我們的指導老師提示道，發明展的評審很多都來自北藝大或者其他學校的不分系，在這些評審中，懂技術的不一定很多，這些評審主要是想要聽到：思考的邏輯、設計的方針、如何解決問題、有沒有思考到解方的利弊，那因為我們在後續著重提到了這些，所以評審可能很滿意，那之所以沒有問問題，也許是因為評審真的沒有問題好問，因為可能不懂技術，所以無法問技術相關的問題，那思考方面我們介紹的很清楚，所以評審也沒什麼好問的。\n後續發展因為我們在賽後有被邀請去日本參加世界賽，所以我們會重新設計外觀，我預計會是可以拆成三部分方便我們帶出國跟過海關。那除了外觀重新設計，我們也要來研究如和在使用一片樹莓派的情況下完成電梯的邏輯，在此時此刻我已經有一些想法了。\n那除了持續參加 IEYI 的世界賽，我也打算修改我們的作品說明書並優化過程，最後投稿小論文。想要研究的是：利用攝影機畫面的突破來計算電梯內的人數 和 警急按鈕的使用率資料收集。\n","tags":["比賽","IEYI","創客","金牌"]},{"title":"3D 列印機教學影片","url":"/RayBlog/2024/09/01/3D%20%E5%88%97%E5%8D%B0%E6%A9%9F%E6%95%99%E5%AD%B8%E5%BD%B1%E7%89%87/","content":"3D 列印機教學影片📋 說明我們學校有很多創客工具，但大部分使用的人很少，主要都是相關領域的學生或老師在使用。但我有聽說有很多學生想要用 3D 列印製作一些作品，但不知道怎麼使用 3D 列印機，而網路上的教學又看不是很懂，於是我決定以創客社副社長的名義拍攝 3D 列印機教學影片。我一共拍攝了 3 支影片，分別是 ender3-Max、K1-Max、Bambu-A1。影片中也有教如何使用建模軟體如：Tinkercad，以及如何使用切片軟體對模型進行切片\n\n  Ender-3 v3 max neo教學\n  K1-Max教學\n  Bambu-A1教學\n\n","tags":["創客","社團","教學"]},{"title":"Deep-Simultaneous-Translation","url":"/RayBlog/2025/05/20/Deep-Simultaneous-Translation/","content":"Deep-Simultaneous-Translation\n    好開心\n\n\n\n📋 前言在國際會議場景中，講者可以自然地使用母語發言，與會者戴上耳機後將聽到保持講者原始音色的即時多語言翻譯。這種沉浸式的翻譯體驗讓聽眾下意識地感受到講者直接用目標語言在溝通，消除了傳統翻譯的疏離感。相比傳統同聲傳譯，這種技術不僅保持了講者的語調情感和個人特色，更大幅提升了跨語言溝通的效率和親和力，讓國際交流變得更加自然流暢。\ngit clone https://github.com/if-else-master/Deep-Simultaneous-Translation.git\n\n\n\n即時語音克隆翻譯系統這是一個革命性的即時語音翻譯系統，能夠邊聽邊翻譯邊輸出，並在保留說話者原始音色的情況下，將語音內容實時翻譯成多種語言。系統採用最先進的AI模型來實現語音識別、翻譯和合成的無縫整合。\n✨ 主要功能\n🎤 即時語音處理：真正的邊聽邊翻譯邊輸出，支持同時進行音頻捕獲、翻譯處理和語音播放\n🎭 高精度音色克隆：僅需3-5秒音頻樣本即可克隆用戶音色\n🌍 多語言支持：支持 9 種語言互譯（中文、英文、日文、韓文、西班牙文、法文、德文、意大利文、葡萄牙文）\n🤖 斷點檢測：自動識別語音開始和停頓，無需手動控制\n⚡ 多線程架構：音頻捕獲、翻譯處理、語音播放並行進行\n🔒 安全性：API Key 安全輸入，臨時文件自動清理\n\n🎯 核心特色真正的即時翻譯\n用戶說話時系統同時進行音頻捕獲\n檢測到語音停頓（1秒）後立即開始翻譯處理\n翻譯完成後使用用戶克隆的語音立即播放\n用戶可以在系統播放翻譯的同時繼續說話\n\n智能語音活動檢測\n自動檢測語音開始和結束\n最小語音長度過濾（0.3秒）避免雜音干擾\n可調節的靜音閾值和持續時間\n\n🏗️ 技術架構本專案結合了多個先進的AI模型和技術：\n1. XTTS-v2 (Coqui TTS)\n用於語音合成和音色克隆\n支持多語言語音合成（包括日語、韓語等）\n僅需短音頻樣本即可克隆音色\n\n2. Gemini 2.0 Flash API\n用於語音識別和翻譯\n支持多模態輸入（音頻 + 文本）\n高精度的語音轉文字和翻譯\n\n3. MeCab + unidic-lite\n日語文本分析和處理\n支持高質量的日語語音合成\n自動配置和錯誤處理\nstart.sh 檢查 MeCab 檢測\n\n💻 系統要求\n作業系統：macOS (推薦 M4 Pro)、Linux\nPython：3.10\n記憶體：至少 8GB RAM\n硬碟空間：至少 5GB（用於模型存儲）\n網絡：穩定的網絡連接（用於 API 請求）\n音頻設備：麥克風和揚聲器\n\n🚀 快速安裝1. 克隆專案git clone https://github.com/yourusername/Deep-Simultaneous-Translation.gitcd Deep-Simultaneous-Translation\n\n2. 創建虛擬環境python -m venv .venvsource .venv/bin/activate\n\n3. 安裝依賴項pip install -r requirements.txt\n\n4. macOS 用戶額外設置（日語支持）brew install mecab mecab-ipadic\n\n📋 依賴項清單sounddevicenumpyTTS==0.22.0openai-whispergoogle-generativeaitorch==2.1pyaudiopygamecutletfugashi              # 日語文本處理庫unidic-lite         # 日語詞典，支援 XTTS 日語語音合成\n\n🎯 使用方法啟動系統方法一：使用啟動腳本（推薦）\nchmod +x start.sh./start.sh\n\n方法二：直接運行\npython main.py\n\n操作流程\n📡 設置 Gemini API Key\n\n系統會提示您安全輸入 API Key\n從 Google AI Studio 獲取\n\n\n🌍 選擇語言\n支持的語言:zh: 中文    en: 英文    ja: 日文ko: 韓文    es: 西班牙文  fr: 法文de: 德文    it: 意大利文  pt: 葡萄牙文\n\n🎭 克隆語音（按 c）\n\n用自然語調說一段話（3-5秒）\n系統會自動檢測語音開始和結束\n語音樣本將保存在 cloned_voices/ 目錄\n\n\n⚡ 開始即時翻譯（按 Enter）\n\n系統進入持續監聽模式\n開始說話，停頓1秒後自動翻譯\n使用您的克隆語音即時播放翻譯結果\n\n\n\n🎛️ 操作界面📋 操作選項:  c - 克隆語音（必須先完成）  enter - 開始即時翻譯  q - 退出程序✅ 語音已克隆，可以開始即時翻譯\n\n🔧 核心代碼架構多線程即時處理# 三個並行工作線程1. audio_capture_worker()    # 音頻捕獲線程2. translation_worker()      # 翻譯處理線程  3. playback_worker()         # 音頻播放線程\n\n🎙️ 聲音斷點檢測技術本系統採用了先進的語音活動檢測 (Voice Activity Detection, VAD) 算法來實現自動斷點識別和翻譯觸發。\n核心技術原理1. RMS (Root Mean Square) 音量計算def calculate_rms(self, audio_data):    &quot;&quot;&quot;計算音頻RMS值 - 音量強度的數學表示&quot;&quot;&quot;    audio_np = np.frombuffer(audio_data, dtype=np.int16)    mean_square = np.mean(audio_np.astype(np.float64)**2)    return np.sqrt(mean_square)\n\n數學公式：\nRMS = √(∑(xi²)/N)\n\nxi：每個音頻樣本的振幅值\nN：樣本總數\nRMS值反映音頻信號的能量強度\n\n2. 語音活動檢測算法def detect_voice_activity(self, audio_data):    &quot;&quot;&quot;智能語音斷點檢測&quot;&quot;&quot;    rms = self.calculate_rms(audio_data)    current_time = time.time()        if rms &gt; self.silence_threshold:  # 檢測到語音        if not self.is_speech_detected:            self.is_speech_detected = True            print(&quot;🎤 開始說話...&quot;)        self.last_speech_time = current_time        return True    else:  # 靜音狀態        if self.is_speech_detected:            silence_duration = current_time - self.last_speech_time            if silence_duration &gt;= self.silence_duration:                self.is_speech_detected = False                print(&quot;⏸️ 檢測到停頓，處理語音...&quot;)                return False        return self.is_speech_detected\n\n3. 關鍵參數配置# 音頻參數self.chunk = 1024              # 音頻塊大小 (樣本數)self.rate = 16000              # 採樣率 16kHzself.silence_threshold = 500   # 靜音閾值 (RMS值)self.silence_duration = 1.0    # 靜音持續時間 (秒)self.min_speech_duration = 0.3 # 最短語音長度 (秒)\n\n技術實現細節1. 音頻緩衝機制from collections import dequeself.audio_buffer = deque(maxlen=int(self.rate * 10))  # 10秒環形緩衝\n\n使用 deque 數據結構實現環形緩衝區\n最大容量：10秒音頻數據\n自動覆蓋舊數據，避免記憶體溢出\n\n2. 實時語音分段def audio_capture_worker(self):    &quot;&quot;&quot;音頻捕獲與分段處理&quot;&quot;&quot;    while self.is_real_time_active:        data = stream.read(self.chunk)        self.audio_buffer.extend(np.frombuffer(data, dtype=np.int16))                is_speech = self.detect_voice_activity(data)                if is_speech:            # 累積語音段            self.current_segment.extend(np.frombuffer(data, dtype=np.int16))        elif self.current_segment and len(self.current_segment) &gt; int(self.rate * self.min_speech_duration):            # 語音段結束，發送處理            segment_audio = np.array(self.current_segment, dtype=np.int16)            self.audio_segments_queue.put(segment_audio)            self.current_segment = []\n\n3. 斷點檢測流程圖音頻輸入 → RMS計算 → 閾值比較 → 狀態判斷 → 動作觸發   ↓           ↓         ↓         ↓         ↓16kHz      數學運算    &gt;500?    語音/靜音    翻譯/等待採樣率      √(∑x²/N)   判斷     狀態機     處理\n\n使用的函式庫音頻處理\nPyAudio：音頻設備介面，實時音頻捕獲\nNumPy：高效數值計算，音頻數據處理\nSciPy：音頻文件讀寫，格式轉換\n\n數據結構\ncollections.deque：環形緩衝區實現\nqueue.Queue：線程間通信\nthreading：多線程並行處理\n\n數學運算import numpy as np# RMS計算rms = np.sqrt(np.mean(audio_array**2))# 音頻數據轉換audio_np = np.frombuffer(raw_audio, dtype=np.int16)\n\n智能優化特性1. 防雜音干擾\n最小語音長度過濾：僅處理超過0.3秒的語音段\nRMS閾值調節：動態適應環境噪音\n連續性檢測：避免短暫雜音觸發翻譯\n\n2. 響應速度優化\n1秒停頓檢測：平衡響應速度與準確性\n實時處理：邊錄音邊分析，無需等待完整句子\n並行架構：音頻捕獲與翻譯處理同時進行\n\n3. 記憶體管理# 環形緩衝區，固定記憶體使用deque(maxlen=160000)  # 約10秒@16kHz# 臨時文件自動清理tempfile.NamedTemporaryFile(delete=False)os.unlink(temp_file.name)\n\n語音斷點檢測演算法的優勢\n低延遲：1秒停頓即觸發，快速響應\n高準確性：RMS + 時間窗口雙重檢測\n抗噪音：智能閾值與最小長度過濾\n資源效率：環形緩衝區，控制記憶體使用\n實時性：無需預先錄製完整音頻\n\n智能語音檢測def detect_voice_activity(self, audio_data):    &quot;&quot;&quot;語音活動檢測&quot;&quot;&quot;    rms = self.calculate_rms(audio_data)    # 音量閾值檢測 + 時間窗口分析    # 自動識別說話開始和停頓\n\n多語言語音合成def synthesize_speech(self, text):    &quot;&quot;&quot;使用克隆語音合成多語言語音&quot;&quot;&quot;    language_map = &#123;        &#x27;zh&#x27;: &#x27;zh-cn&#x27;, &#x27;en&#x27;: &#x27;en&#x27;, &#x27;ja&#x27;: &#x27;ja&#x27;,        &#x27;ko&#x27;: &#x27;ko&#x27;, &#x27;es&#x27;: &#x27;es&#x27;, &#x27;fr&#x27;: &#x27;fr&#x27;,        &#x27;de&#x27;: &#x27;de&#x27;, &#x27;it&#x27;: &#x27;it&#x27;, &#x27;pt&#x27;: &#x27;pt&#x27;    &#125;    # 自動語言檢測 + 錯誤處理\n\n🛠️ 高級功能自動 MeCab 配置系統會自動檢測並配置 MeCab（日語處理）：\ndef setup_mecab():    # 自動檢測 unidic-lite 詞典    # 備用系統 MeCab 配置    # 智能錯誤處理\n\n智能錯誤恢復\n日語處理失敗時自動使用英語合成\nAPI 錯誤重試機制\n臨時文件自動清理\n\n🎵 支持的語言組合\n\n\n原始語言\n目標語言\n狀態\n\n\n\n中文\n日文\n✅ 完全支持\n\n\n中文\n英文\n✅ 完全支持\n\n\n英文\n中文\n✅ 完全支持\n\n\n英文\n日文\n✅ 完全支持\n\n\n其他語言\n任意支持語言\n✅ 完全支持\n\n\n🔍 故障排除常見問題1. MeCab 初始化錯誤\n# 解決方案：系統已自動處理，會使用 unidic-lite 備用詞典\n\n2. 語音合成失敗\n⚠️ 日語處理組件問題，嘗試使用英語合成...🔊 使用英語語音合成完成\n\n3. API Key 無效\n❌ API Key 無效: 400 API key not valid是否重新輸入？(y/n): y\n\n4. 音頻設備問題\n\n檢查麥克風權限\n確認音頻設備工作正常\n在安靜環境中使用\n\n性能優化記憶體優化\n\n臨時文件自動清理\n音頻緩衝區大小限制\n佇列管理\n\n📁 專案結構Deep-Simultaneous-Translation/├── main.py              # 主程序├── start.sh             # 啟動腳本├── requirements.txt     # 依賴項├── README.md           # 使用說明├── XTTS-v2/            # XTTS 模型文件│   ├── config.json│   ├── model.pth│   └── ...├── cloned_voices/      # 克隆語音存儲└── voice_output/       # 音頻輸出（臨時）\n\n🔐 安全與隱私\nAPI Key 安全輸入：使用 getpass 避免明文顯示\n本地音頻處理：語音克隆完全在本地進行\n臨時文件清理：自動清理所有臨時音頻文件\n網絡隱私：僅翻譯時向 Gemini API 發送音頻\n\n🤝 貢獻指南歡迎提交 Issue 和 Pull Request！\n\nFork 本專案\n創建功能分支 (git checkout -b feature/AmazingFeature)\n提交更改 (git commit -m &#39;Add some AmazingFeature&#39;)\n推送到分支 (git push origin feature/AmazingFeature)\n開啟 Pull Request\n\n📜 授權信息\n本專案：GNU GENERAL PUBLIC LICENSE\nXTTS-v2 模型：Coqui Public Model License\nGemini API：遵循 Google AI 使用條款\n\n📞 聯繫方式\nEmail：[rayc57429@gmail.com]\nGitHub Issues：提交問題\n\n🙏 致謝感謝以下開源專案：\n\nCoqui TTS - XTTS-v2 語音合成\nGoogle Gemini - 語音識別和翻譯\nMeCab - 日語文本分析\n\n\n\n\n🎤 即時語音克隆翻譯系統 | Deep-Simultaneous-Translation\n讓語言不再是溝通的障礙\n© 2025 Deep Simultaneous Translation\n\n\n\n\n","tags":["AI","個人專案","教育","軟體","國際交流"]},{"title":"Deep-Video-Translation","url":"/RayBlog/2025/03/05/Deep-Video-Translation/","content":"Deep-Video-Translation\n    在國際交流分享\n\n\n\n📋 前言在數位實驗高中，我們積極推動國際化教育，並與來自世界各地的學校展開交流與合作。為了突破語言障礙，讓更多人了解我們的非同步課程與社團活動，我開始開發一套AI深度影片翻譯系統。這套系統結合語音識別、音色複製、嘴形調整與簡報翻譯等功能，能將中文影片內容翻譯成多國語言，並保留講者原本的音色與風格，打造出高擬真的多語版本教學影片。希望透過這樣的技術，讓我們的課程內容被更多國際觀眾理解與接受，促進跨文化的教育交流。\ngit clone https://github.com/if-else-master/Deep-Video-Translation.git\n\n\nAI 深度影片翻譯系統，集成語音識別、語音複製、嘴形調整和 OCR 簡報翻譯功能。\n🎯 專案特色\n🎤 多語言語音識別與翻譯：支援中文、英文、日文的語音識別和翻譯\n🗣️ AI 語音克隆：使用 XTTS-v2 模型進行高品質語音合成\n👄 嘴形同步：利用 Wav2Lip 技術實現精確的唇語同步\n📊 OCR簡報翻譯：自動識別簡報頁面並進行 OCR 文字翻譯\n🧠 智能分段處理：自動區分人臉講話與簡報展示，分別處理後智能合併\n🎬 多重合併策略：解決不同解析度視頻合併問題，確保完整輸出\n🖥️ 圖形化界面：tkinter GUI 操作介面\n\n🛠️ 技術架構核心開源組件\n\n\n組件\n功能\n官方連結\n\n\n\nGemini API\n語音識別與文字翻譯\nGoogle Gemini\n\n\nXTTS-v2\n語音克隆與合成\nCoqui TTS\n\n\nWav2Lip\n嘴形同步技術\nWav2Lip\n\n\nEasyOCR\n光學字符識別\nEasyOCR\n\n\nOpenCV\n計算機視覺處理\nOpenCV\n\n\nPIL&#x2F;Pillow\n圖像處理\nPillow\n\n\n工具與框架\nPython 3.10\nPyTorch - 深度學習框架\nFFmpeg - 音視頻處理\ntkinter - GUI 界面\nNumPy - 數值計算\nImageHash - 圖像哈希比較\n\n🚀 功能展示1. 語音識別與翻譯def voice(voice_file, api_key, target_language=&quot;日文&quot;):    client = genai.Client(api_key=api_key)    myfile = client.files.upload(file=voice_file)        # 等待文件處理完成    while myfile.state == &quot;PROCESSING&quot;:        time.sleep(2)        myfile = client.files.get(name=myfile.name)        language_prompts = &#123;        &quot;日文&quot;: &quot;將音檔內容輸出成逐字稿並翻譯成日文，最後只要輸出翻譯過後的逐字稿&quot;,        &quot;英文&quot;: &quot;將音檔內容輸出成逐字稿並翻譯成英文，最後只要輸出翻譯過後的逐字稿&quot;,        &quot;中文&quot;: &quot;將音檔內容輸出成逐字稿，如果原本就是中文就直接輸出逐字稿，如果是其他語言就翻譯成中文&quot;    &#125;        prompt = language_prompts.get(target_language, language_prompts[&quot;日文&quot;])    response = client.models.generate_content(        model=&quot;gemini-2.0-flash-lite&quot;, contents=[prompt, myfile]    )    return response.text\n\n2. 語音克隆 (XTTS-v2)def xttsv(text, reference_audio, output_audio, language=&quot;日文&quot;):    from TTS.tts.configs.xtts_config import XttsConfig    from TTS.tts.models.xtts import Xtts        # 載入模型    config = XttsConfig()    config.load_json(&quot;app/XTTS-v2/config.json&quot;)    model = Xtts.init_from_config(config)    model.load_checkpoint(config, checkpoint_dir=&quot;app/XTTS-v2/&quot;, eval=True)        # 語音合成    outputs = model.synthesize(        text,        config,        speaker_wav=reference_audio,        gpt_cond_len=3,        language=language_code,    )        # 保存音頻    torchaudio.save(output_audio, torch.tensor(outputs[&quot;wav&quot;]).unsqueeze(0), 24000)    return output_audio\n\n3. 嘴形同步 (Wav2Lip)def run_inference(face_path, audio_path, output_path):    # 載入視頻    video_stream = cv2.VideoCapture(face_path)    fps = video_stream.get(cv2.CAP_PROP_FPS)        # 讀取所有幀    full_frames = []    while True:        still_reading, frame = video_stream.read()        if not still_reading:            break        full_frames.append(frame)        # 處理音頻    wav = audio.load_wav(audio_path, 16000)    mel = audio.melspectrogram(wav)        # 載入 Wav2Lip 模型    model = load_model(&quot;app/Wav2Lip/checkpoints/wav2lip.pth&quot;)        # 生成同步視頻    for img_batch, mel_batch, frames, coords in datagen(full_frames, mel_chunks):        pred = model(mel_batch, img_batch)        # 將預測結果合成到原始幀中        for p, f, c in zip(pred, frames, coords):            y1, y2, x1, x2 = c            p = cv2.resize(p.astype(np.uint8), (x2 - x1, y2 - y1))            f[y1:y2, x1:x2] = p            out.write(f)\n\n4. 智能分段處理系統🧠 智能分段處理架構系統的核心創新在於智能分段處理，能夠自動分析視頻內容，區分「人臉講話片段」和「簡報展示片段」，分別進行最適合的處理方式，最後智能合併為完整視頻。\n處理流程概覽\ndef analyze_and_segment_video(self, video_path):    &quot;&quot;&quot;分析影片並智能分段，分離人臉和簡報片段&quot;&quot;&quot;    segments = []    current_segment = None        for frame_count, frame in enumerate(video_frames):        # 檢測內容類型        has_faces = self.detect_faces_in_frame(frame)        is_slide = self.is_slide_frame(frame)                # 決定段落類型        if has_faces:            segment_type = &quot;face&quot;     # 人臉講話片段        elif is_slide:            segment_type = &quot;slide&quot;    # 簡報展示片段        else:            segment_type = &quot;unknown&quot;  # 未知內容                # 智能分段邏輯        if self.should_create_new_segment(current_segment, segment_type, frame):            segments.append(current_segment)            current_segment = self.create_new_segment(segment_type, frame_count)        return segments\n\n分段決策算法\n\n\n\n檢測項目\n技術方法\n判斷條件\n處理策略\n\n\n\n場景變化\nImageHash\nabs(curr_hash - prev_hash) &gt; threshold\n觸發新段落\n\n\n人臉檢測\nHaar Cascade\nlen(faces) &gt; 0\n嘴形同步處理\n\n\n簡報檢測\n邊緣密度分析\n0.01 &lt; edge_ratio &lt; 0.3\nOCR翻譯處理\n\n\n最小時長\n幀數統計\nframes &gt;= min_duration * fps\n段落有效性\n\n\n🔍 人臉與簡報識別技術系統使用多層次檢測機制來區分「人臉講話畫面」和「簡報展示畫面」：\n人臉檢測技術\ndef detect_faces_in_frame(self, frame):    &quot;&quot;&quot;檢測幀中是否有人臉&quot;&quot;&quot;    # 使用 OpenCV 的 Haar Cascade 分類器    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + &#x27;haarcascade_frontalface_default.xml&#x27;)    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    faces = face_cascade.detectMultiScale(gray, 1.1, 4)    return len(faces) &gt; 0\n\n簡報頁面判斷邏輯\ndef is_slide_frame(self, frame):    &quot;&quot;&quot;判斷是否為簡報頁面（沒有人臉且有文字內容）&quot;&quot;&quot;    # 第一步：人臉檢測    has_faces = self.detect_faces_in_frame(frame)    if has_faces:        return False  # 有人臉，不是簡報        # 第二步：文字內容檢測    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    edges = cv2.Canny(gray, 50, 150)  # Canny 邊緣檢測    edge_ratio = np.sum(edges &gt; 0) / edges.size        # 邊緣比例在合理範圍內，判定為簡報    # 太少邊緣可能是空白，太多邊緣可能是雜亂背景    return 0.01 &lt; edge_ratio &lt; 0.3\n\n多層次檢測機制\n\n\n\n檢測層次\n技術方法\n判斷標準\n\n\n\n1. 影像變化檢測\nImageHash\nabs(curr_hash - prev_hash) &gt; threshold\n\n\n2. 人臉存在檢測\nHaar Cascade\nlen(faces) &gt; 0\n\n\n3. 文字內容檢測\nCanny 邊緣檢測\n0.01 &lt; edge_ratio &lt; 0.3\n\n\n決策樹邏輯\n影像幀 → 影像有變化? → 檢測到人臉? → 邊緣比例適中?   ↓           ↓           ↓           ↓ 跳過      人臉講話畫面   簡報頁面   空白/雜亂畫面                           ↓                     進行OCR翻譯\n\n技術原理說明\n\nHaar Cascade: 使用預訓練的人臉檢測模型，參數 (1.1, 4) 分別為縮放因子和最少檢測矩形數\nCanny 邊緣檢測: 參數 (50, 150) 為低&#x2F;高閾值，簡報文字會產生適量邊緣\n邊緣比例閾值: 0.01-0.3 範圍避免空白頁面和複雜背景的誤判\n\n投影片處理流程\ndef process_slide_image(self, image_path, output_path, target_lang):    &quot;&quot;&quot;處理單張投影片圖片&quot;&quot;&quot;    img = cv2.imread(image_path)    reader = easyocr.Reader([&#x27;ch_tra&#x27;], gpu=False)    results = reader.readtext(img)        # 提取文字區域    boxes, orig_texts = [], []    for box, text, conf in results:        if conf &gt; 0.4:            boxes.append(box)            orig_texts.append(text)        # 移除原文並進行修復    img_clean = self.remove_text_with_inpainting(img, boxes)        # 翻譯文字    translated = [self.translate_with_gemini(t, target_lang) for t in orig_texts]        # 重新繪製翻譯後的文字    pil_img = Image.fromarray(cv2.cvtColor(img_clean, cv2.COLOR_BGR2RGB))    final = self.draw_translated_text(pil_img, boxes, translated, font_path)    final.save(output_path)\n\n分段提取與處理\ndef extract_segments(self, video_path, segments, face_dir, ppt_dir):    &quot;&quot;&quot;提取並儲存影片段落，每個段落包含完整的音視頻&quot;&quot;&quot;    cap = cv2.VideoCapture(video_path)    fps = cap.get(cv2.CAP_PROP_FPS)        for segment in segments:        start_frame = segment[&#x27;start_frame&#x27;]        end_frame = segment[&#x27;end_frame&#x27;]        start_time = start_frame / fps        duration = (end_frame - start_frame + 1) / fps                if segment[&#x27;type&#x27;] == &#x27;face&#x27;:            output_path = os.path.join(face_dir, f&quot;&#123;face_count:02d&#125;.mp4&quot;)        elif segment[&#x27;type&#x27;] == &#x27;slide&#x27;:            output_path = os.path.join(ppt_dir, f&quot;&#123;slide_count:02d&#125;.mp4&quot;)                # 使用 FFmpeg 提取完整音視頻段落        command = f&#x27;ffmpeg -y -i &quot;&#123;video_path&#125;&quot; -ss &#123;start_time&#125; -t &#123;duration&#125; -c:v libx264 -c:a aac &quot;&#123;output_path&#125;&quot;&#x27;        subprocess.run(command, shell=True)\n\n🎭 人臉段落處理流程步驟1：音頻提取與翻譯\ndef process_face_segments(self, face_dir, language):    for segment_file in face_files:        # 1. 語音轉文字並翻譯        translated_text = voice(segment_file, api_key, language)                # 2. 語音克隆        audio_path = xttsv(translated_text, segment_file, temp_audio, language)                # 3. 嘴形同步        run_inference(segment_file, audio_path, processed_path)\n\n📊 簡報段落處理流程步驟1：音頻處理\ndef process_slide_segments(self, ppt_dir, language, slide_language):    for segment_file in ppt_files:        # 1. 語音轉文字並翻譯        translated_text = voice(segment_file, api_key, language)                # 2. 語音克隆        if translated_text:            audio_path = xttsv(translated_text, segment_file, temp_audio, language)\n\n步驟2：OCR翻譯處理\ndef process_slide_video(self, input_video, output_video, target_lang, audio_path):    &quot;&quot;&quot;處理簡報影片，進行OCR翻譯&quot;&quot;&quot;    cap = cv2.VideoCapture(input_video)        # 逐幀處理OCR翻譯    while True:        ret, frame = cap.read()        if not ret: break                # 檢測場景變化        if frame_count % 10 == 0:            curr_hash = imagehash.phash(frame)            if abs(curr_hash - prev_hash) &gt; threshold:                # 進行OCR翻譯                translated_frame = self.translate_frame_text(frame, target_lang)                current_translated_frame = translated_frame                         # 輸出翻譯後的幀         output_frame = current_translated_frame if current_translated_frame else frame         out.write(output_frame)\n\n🎬 智能合併系統處理完所有段落後，系統需要將不同解析度的視頻段落智能合併。這是技術挑戰最大的部分。\n解析度統一技術\n不同處理方式會導致不同的輸出解析度：\n\n人臉段落: Wav2Lip 輸出通常為 640x360\n簡報段落: 原始解析度可能為 1280x720 或更高\n\n多重合併策略\ndef auto_edit_segments(self, face_segments, slide_segments, segments_info, output_path):    &quot;&quot;&quot;根據原始順序自動剪接所有段落&quot;&quot;&quot;        # 方法1：Filter Complex 統一解析度合併    if len(ordered_segments) == 2:        command = f&#x27;&#x27;&#x27;ffmpeg -y -i &quot;&#123;segments[0]&#125;&quot; -i &quot;&#123;segments[1]&#125;&quot;         -filter_complex &quot;[0:v]scale=1280:720,setsar=1:1[v0];                        [1:v]scale=1280:720,setsar=1:1[v1];                        [0:a]aformat=sample_fmts=fltp:sample_rates=22050:channel_layouts=mono[a0];                        [1:a]aformat=sample_fmts=fltp:sample_rates=22050:channel_layouts=mono[a1];                        [v0][a0][v1][a1]concat=n=2:v=1:a=1[outv][outa]&quot;         -map &quot;[outv]&quot; -map &quot;[outa]&quot; -c:v libx264 -c:a aac &quot;&#123;output_path&#125;&quot;&#x27;&#x27;&#x27;        # 方法2：預處理統一解析度    normalized_segments = []    for segment in ordered_segments:        normalized_path = segment.replace(&#x27;.mp4&#x27;, &#x27;_normalized.mp4&#x27;)        command = f&#x27;&#x27;&#x27;ffmpeg -y -i &quot;&#123;segment&#125;&quot;         -vf scale=1280:720:force_original_aspect_ratio=decrease,            pad=1280:720:(ow-iw)/2:(oh-ih)/2,setsar=1:1         -af aformat=sample_fmts=fltp:sample_rates=22050:channel_layouts=mono         -c:v libx264 -c:a aac &quot;&#123;normalized_path&#125;&quot;&#x27;&#x27;&#x27;        # 方法3：逐個兩兩合併    # 方法4：直接複製備用方案\n\n合併技術原理\n\n\n\n方法\n技術核心\n優點\n缺點\n\n\n\nFilter Complex\nFFmpeg濾鏡鏈一次性處理\n效率高，質量好\n複雜視頻可能失敗\n\n\n預處理統一\n先統一再concat\n兼容性好\n需要額外存儲空間\n\n\n逐個合併\n兩兩遞歸合併\n最穩定可靠\n處理時間較長\n\n\n直接複製\n最後備用方案\n絕對不會失敗\n僅保留首個段落\n\n\n解析度統一算法\n# 保持寬高比的智能縮放scale=1280:720:force_original_aspect_ratio=decrease# 居中填充黑邊pad=1280:720:(ow-iw)/2:(oh-ih)/2# 統一像素寬高比setsar=1:1# 統一音頻格式aformat=sample_fmts=fltp:sample_rates=22050:channel_layouts=mono\n\n📦 安裝指南環境要求Python 3.10CUDA (可選，用於 GPU 加速)FFmpeg註：本專案在 Macbook M4 開發\n\n安裝步驟\n克隆專案\n\ngit clone https://github.com/if-else-master/Deep-Video-Translation.gitcd Deep-Video-Translation\n\n\n安裝依賴\n\npip install -r requirements.txt\n\n\n下載模型文件\n\n# Wav2Lip 模型wget https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp2pgHDTDA -O app/Wav2Lip/checkpoints/wav2lip.pth# XTTS-v2 模型會自動下載\n\n\n準備字體文件\n\n# 下載 Noto 字體到 app 目錄wget https://github.com/googlefonts/noto-cjk/releases/download/Sans2.004/03_NotoSansCJKjp.zipunzip 03_NotoSansCJKjp.zip -d app/\n\n🎮 使用方法命令行模式python app/main.py\n\nGUI 操作流程\n輸入 Gemini API Key\n選擇輸入影片 (支援 MP4 格式)\n設定語音翻譯語言 (中文&#x2F;英文&#x2F;日文)\n智能分段設定\n啟用投影片翻譯: 開啟OCR文字翻譯功能\n投影片翻譯語言: 設定OCR翻譯目標語言\n最小段落長度: 設定分段的最小時間長度(秒)\n場景切換門檻: 調整場景變化檢測靈敏度\n\n\n設定輸出路徑\n開始智能分段處理\n\n智能分段處理階段程序會依序執行以下階段：\n階段1：智能分析與分段 (0-20%)\n\n逐幀分析影片內容\n檢測人臉和簡報場景\n根據場景變化和最小時長進行智能分段\n提取完整音視頻段落到不同目錄\n\n階段2：人臉段落處理 (20-70%)\n\n對每個人臉段落進行語音識別和翻譯\n使用XTTS-v2進行語音克隆\n通過Wav2Lip實現嘴形同步\n\n階段3：簡報段落處理 (70-90%)\n\n對每個簡報段落進行語音識別和翻譯\n使用XTTS-v2進行語音克隆\n如啟用OCR翻譯，逐幀進行文字識別和翻譯重繪\n\n階段4：智能合併 (90-100%)\n\n解析度統一處理\n多重合併策略確保成功\n按原始順序組合所有段落\n\n智能分段處理流程graph TD    A[輸入影片] --&gt; B[智能內容分析]    B --&gt; C[場景變化檢測]    C --&gt; D[人臉/簡報識別]    D --&gt; E[智能分段]    E --&gt; F[提取音視頻段落]        F --&gt; G[人臉段落處理]    F --&gt; H[簡報段落處理]        G --&gt; G1[語音識別與翻譯]    G1 --&gt; G2[語音克隆 XTTS-v2]    G2 --&gt; G3[嘴形同步 Wav2Lip]        H --&gt; H1[語音識別與翻譯]    H1 --&gt; H2[語音克隆 XTTS-v2]    H2 --&gt; H3&#123;啟用OCR翻譯?&#125;    H3 --&gt;|是| H4[OCR文字識別]    H4 --&gt; H5[文字翻譯與重繪]    H5 --&gt; H6[逐幀翻譯合成]    H3 --&gt;|否| H6        G3 --&gt; I[解析度統一處理]    H6 --&gt; I    I --&gt; J[多重合併策略]    J --&gt; K[輸出最終視頻]\n\n📁 專案結構Deep-Video-Translation/├── app/│   ├── main.py                    # 主程式 GUI 界面│   ├── txtvoice.py               # Gemini 語音識別模組│   ├── xttsv.py                  # XTTS 語音克隆模組│   ├── ImageHash_ppt.py          # 投影片翻譯工具│   ├── Wav2Lip/                  # Wav2Lip 嘴形同步│   │   ├── inference.py          # 推理主程式│   │   ├── models/               # 模型定義│   │   ├── checkpoints/          # 預訓練模型│   │   └── face_detection/       # 人臉檢測│   ├── XTTS-v2/                  # XTTS 模型文件│   ├── NotoSansCJKjp-Regular.otf # 日文字體│   └── NotoSansTC-Regular.ttf    # 中文字體├── temp/                         # 臨時文件目錄│   ├── faceai/                   # 人臉段落處理目錄│   ├── pptai/                    # 簡報段落處理目錄│   ├── audio_segments/           # 音頻片段目錄│   ├── slides_output/            # 提取的投影片目錄│   ├── translated_slides/        # 翻譯後的投影片目錄│   └── segments/                 # 其他分段文件├── requirements.txt              # Python 依賴└── README.md                     # 說明文件\n\n🔬 技術創新與原理核心技術創新1. 智能分段算法結合多種計算機視覺技術實現影片內容的智能識別：\n\nImageHash: 使用感知哈希檢測場景變化\nHaar Cascade: 人臉檢測確定講話片段\nCanny邊緣檢測: 分析邊緣密度判斷簡報內容\n時間連續性: 最小段落長度避免過度分段\n\n2. 解析度統一技術解決不同AI模型輸出解析度不一致的問題：\n\n智能縮放: force_original_aspect_ratio=decrease 保持原始比例\n居中填充: 自動計算填充位置保持視覺效果\n音頻格式統一: 統一採樣率和聲道確保兼容性\n\n3. 多重容錯機制四層合併策略確保處理成功率：\n\nFilter Complex: 最高效率的一次性處理\n預處理統一: 最佳兼容性的分步處理\n逐個合併: 最高穩定性的遞歸處理\n備用方案: 絕對不會失敗的保險機制\n\n4. 逐幀OCR翻譯實現連續視頻的文字翻譯：\n\n場景變化檢測: 只在必要時進行OCR處理\n翻譯緩存: 避免重複處理相同內容\n文字修復: 使用inpainting技術移除原文\n字體適配: 多語言字體自動選擇\n\n技術難點突破問題1：不同模型輸出格式不統一解決方案: 實現了自適應解析度統一系統\n# 智能縮放保持比例scale=1280:720:force_original_aspect_ratio=decrease# 居中填充到統一尺寸pad=1280:720:(ow-iw)/2:(oh-ih)/2\n\n問題2：視頻合併兼容性差解決方案: 四重合併策略確保成功\n\n先嘗試高效方法，失敗後自動降級\n每種方法針對不同場景優化\n最後的直接複製確保絕不失敗\n\n問題3：OCR翻譯效果不連續解決方案: 基於場景檢測的智能翻譯\n\n場景不變時重複使用翻譯結果\n場景變化時重新進行OCR處理\n逐幀輸出確保視頻連續性\n\n性能優化策略\n並行處理: 人臉和簡報段落可並行處理\n智能採樣: 不是每幀都進行檢測，提高效率\n內存管理: 及時清理臨時文件避免空間不足\n容錯設計: 單個段落失敗不影響整體處理\n\n未來目標\n加上 RAG (檢索增強生成)\n支援更多視頻格式\n實現批量處理功能\n添加Web界面\n優化處理速度\n\n📄 授權條款本專案採用 GPLv3 授權條款 - 詳見 LICENSE 文件\n🙏 致謝\nWav2Lip - 嘴形同步技術\nXTTS-v2 - 語音克隆模型\nEasyOCR - OCR 文字識別\nGoogle Gemini - 語音識別與翻譯 API\n\n📞 聯絡方式如有問題或建議，請透過以下方式聯絡：\n\n提交 GitHub Issue\n電子郵件：rayc57429@gmail.com\n\n\n⭐ 如果這個專案對您有幫助，請給我們一顆星星！\n","tags":["AI","個人專案","教育","軟體","國際交流"]},{"title":"XR實境教育創意大賞競賽","url":"/RayBlog/2024/03/20/XR%E5%AF%A6%E5%A2%83%E6%95%99%E8%82%B2%E5%89%B5%E6%84%8F%E5%A4%A7%E8%B3%9E%E7%AB%B6%E8%B3%BD/","content":"XR實境教育創意大賞競賽\n    榮獲優勝\n\n\n📋 前言這次的這個比賽是跟元宇宙有關，可以是一個場景、一個故事、一個教材甚至是一個世界。主辦方希望我們做一個跟教育有關的XR專題，在後疫情時代讓我們看見遠距學習之重要性， 如何於課堂上與師生即時互動，並且落實完整教學需求，讓虛擬課程不遜色於實體課程，進而克服實體教學所遇到之侷限與困境，協助學生建構知識，提升學習成效，成為現階段建立教育元宇宙的核心課題。以上的敘述是我們在這個比賽中要實現的目標。\n\n\n關於比賽這次的這個比賽是跟元宇宙有關，可以是一個場景、一個故事、一個教材甚至是一個世界。主辦方希望我們做一個跟教育有關的XR專題，在後疫情時代讓我們看見遠距學習之重要性， 如何於課堂上與師生即時互動，並且落實完整教學需求，讓虛擬課程不遜色於實體課程，進而克服實體教學所遇到之侷限與困境，協助學生建構知識，提升學習成效，成為現階段建立教育元宇宙的核心課題。以上的敘述是我們在這個比賽中要實現的目標。\n\n準備過程在這個比賽中我們希望做到科技與人文的結合，而VR和AR就是很好的媒介，在這次的比賽中我們會融入AR的技術，做出有點像 QRcode 的感覺，掃一下就可以得知這個物品的資訊。經過跟故事組的討論我們決定以士林八芝蘭作為主題，故事組寫了一個上世紀90年代一家三口的故事，講述了當時的士林以及當時的一些觀光景點比如圓山舊兒童。故事以舊兒童樂園為主題述說了一個感人且富有教育意義的歷史知識。而我在這次的比賽中的工作是將故事組的場景在VR中呈現出來，而因為我們這次加入了AR所以我們還要做AR的掃描圖卡。VR我們使用空間球的方式呈現，AR則是用掃描圖卡的方式。那我們使用了一套很創新的MAKAR來完成這些功能。最後很順利的完成了。\n\n比賽過程這次的比賽在高雄，我早上六點從桃園高鐵站南下去高雄。但這次比賽就很不順利了，我們的簡報在轉檔的過程中發生錯誤，提交出去的檔案變成亂碼，所以我們只能有PDF來做簡報，但這樣我們的影片就放不了，那因為發生這種狀況，所以我們隨機應變，增加了實際操作的介紹以及比重。那除了簡報的部分不完美，剩下的都很不錯，我們現場演了我們故事中的最後一段女兒陪父親到遊樂園回憶過去的劇情，受到了評審們的熱烈掌聲，算是有驚無險的完成比賽了。\n\n比賽心得在這次的比賽中，我們的技術佔比很少基本上是圍繞的人文與藝術相關的內容來製作這個比賽，那我想我在跨域合作這方面也越來越成熟了，我這次還能客串一下故事組的部分，真的是很神奇，這次比賽讓我知道了科技跟人文不是水火不容的東西，只要經過處理，科技跟人文是可以做出很高價值的產品的。在這次的高雄之旅中，我們還有看到很多很不錯的作品，像是利用VR結合google map 做一個跨時空的旅行。那我想我高中的虛擬實境篇應該就到這邊結束了，接下來我會著重於創客手作、軟體開發、資料庫設計、大型語言模型、區塊鏈等專案。\n","tags":["比賽","ARVR","虛擬實境","社會議題"]},{"title":"個人專案分享及比賽心得記錄","url":"/RayBlog/2025/06/07/title/","content":"\n\n\n成功沒有捷徑，但通勤不能沒有 Wi-Fi！\n\n\n\n\n"},{"title":"國際交流-大宮北高校","url":"/RayBlog/2025/03/11/%E5%9C%8B%E9%9A%9B%E4%BA%A4%E6%B5%81-%E5%A4%A7%E5%AE%AE%E5%8C%97%E9%AB%98%E6%A0%A1/","content":"國際交流-大宮北高校\n    個人專案分享\n\n\n📋 前言這次的國際交流是由我們台北市數位實驗高級中等學校主辦，跟日本埼玉市立大宮北高等學校進行國際交流。這次的活動除了我們學校的必修課程介紹之外，還有我們學生在課後之餘進行的個人研究或個人專案，而大宮北高校的學生也有準備他們的自主學習並以此進行學生之間的交流。而我們也融合了我們學校的社團或是多元選修課程來進行更多的互動，像是：創客社、食話食說、定向越野等…。\n\n\n準備工作我很高興我今年能以個人研究講者以及創客社副社長的身份參加這次國際交流，而我分享的專案是我的 AI深度影片翻譯模型，這個專案本身就是為了國際學習而開發的，放在這次國際交流展示我覺得在適合不過了。 我跟我們學校的生物課老師以及必修課老師討論，是否能使用兩位老師的非同步影片課程進行展示，選擇使用這兩堂課老師的教材是因為他們都有露臉，且都是我們學校的特色課程。我們的「生物課」也並非普高的生物課，結合了 IB 教材以及台灣課綱以外的專業知識，必修課則是我們學校的基礎課程「設計思考」，能實際帶日本學生進行我們學校的課程，並進行互動。而這次除了分享我的個人專案之外還有創客社的活動，在社團活動中，我們用雷射切割和 3D 列印機設計了很多桌遊和可以租裝的數實小吊飾，而我設計了帶有數實 LOGO 的鍵盤按鈕，可以掛在書包之類的地方，然後在藉由桌遊認識彼此。\n逐字講稿Hello! I’m 張靖杭, but you can call me Ray.I’m excited to share my topic today: “Deep Video AI Translation”At T-School, about 60% of our courses are Async(e think) video lessons. we need to watchvideos for learning.so I think if we could translate these videos into different languages withAI！ This will allow more people to see our school’s special course.Here are the four things I have down in this project:1.Clone Voice2.Multilingual Translation3.Lip Synchronization4.Global SharingI’ve set out to develop this project using open-source models. First, I discovered Real-Time-Clone on GitHub, but I think this model is not the best chooseNow, I want to share with you the three goals of this project.1.To copy the original(a real g no) voiceI kept searching and found XTTS-V2 from Hugging Face, This models have 18 languages can use a perfect match for what I need!1.To translateI use OpenAI’s API to translate video language.\n\nTo make you feel like he’s actually speaking in Japanese, you can see his mouth is differentFor the third goal, I use the open-source VideoRetake model from GitHub. After thorough secondary development and debugging, I’m happy to say that the project is endBelow, you’ll find videos showcasing the before and after of the translations. Anyone want to guess how long it takes to export a 5 second video? If you are interested you can scan(掃描) the QR code and follow my github and instagramThank you so much for your listen!\n\n\n心得感想去年我沒有參加到大宮北的國際交流，這次我參加到了，在活動之前我花了很多時間矯正我的口音，因為我知道我的英文發音有點不清楚，直到交流前我的很多音還是發不出來，但我盡量換句話說，希望能將這個深度翻譯影片的專案詳細介紹給大宮北的學生和老師。日本的學生對於開源模型的使用十分好奇，因此我現場有脫稿的情況，因為想要回應日本學生的疑問，以及針對他們有興趣的部分去介紹，像是 hugging face 上模型的使用 github 上的開源專案等。 大宮北高校本身也是注重科技相關的學校並且也重視國際交流，他們的老師對於這個深度影片翻譯的專案非常有興趣，並且提出明年使用該專案進行課程分享，讓我們數位實驗高中的學生也能體驗大宮北高校的特別課程，而我們學校也能拿出特別的必修課出來分享，讓課程交流的環節更進一步。 在為來學校的 RTX5090 到貨後我預計針對這個顯卡做針對性的調整，讓輸出的效率更高，但在那之前，我會先完善該專案在本地關的使用體驗。\n新聞報導台湾サイエンス１日目日高校參訪北市數位實中 交流專題體驗臺灣美食數位實中-日台友誼再續新篇章：大宮北高校與數位實中以創客專題與飲食文化進行國際交流\n","tags":["AI","個人專案","教育","國際交流"]},{"title":"APP Inventor 創作徵選計畫之[黑客松選拔競賽]","url":"/RayBlog/2023/11/11/APP%20Inventor%20%E5%89%B5%E4%BD%9C%E5%BE%B5%E9%81%B8%E8%A8%88%E7%95%AB%E4%B9%8B%5B%E9%BB%91%E5%AE%A2%E6%9D%BE%E9%81%B8%E6%8B%94%E7%AB%B6%E8%B3%BD%5D/","content":"APP Inventor 創作徵選計畫之[黑客松選拔競賽]\n    榮獲佳作\n\n\n📋 前言學會製作網站以及windows軟體後，我開始想往APP的放向學習，因此我從相對容易學習的APP Inventor來學習。在這個比賽中我們這組是製作樂齡的 APP ，希望年長者可以透過這個APP來學習、交流以及互動。我們設計了許多的獎勵機制，比如設計&#x2F;拍攝課程可以獲得點數，而點數可以學習更多的內容或者換取物資。希望藉由這個APP讓長者實現活到老學到老。\n\n\n關於比賽這個比賽由教育部資訊及科技教育司主辦。為了落實十二年國教的精神，鼓勵教師將運算思維和程式設計融入教學中，擴展各學習領域的深度與廣度，並提升學生解決問題的能力，並同時宣導尊重智慧財產權的重要性，推廣自由軟體的使用，減少非法軟體在校園中的使用，以培養學生對知識產權的正確認識。此外，透過科技工具的創意應用，致力於提升學生在生活觀察、邏輯思考和創作能力方面的表現。為進一步激發學生的學習動機，舉辦黑客松活動，結合徵選與現場實作，讓更多學生參與觀摩程式設計及分享交流，促進創意與知識的互動發展。\n準備過程我們的隊員中有一位因為家中的年長者長期待在家，又因為老伴的離開而罹患憂鬱症。我們想要製作一款方便且能直覺操作的 APP，而功能包含：製作教學影片、觀看教學影片、獎勵制度、匹配制度。我們還會製作使用者後台， 透過 SQL 讓使用者能隨時更改設定。我在這次的團隊比賽中的工作是 APP 的邏輯編寫以及資料庫的建置。\n比賽作品在使用 APP Inventor 的時候我們遇到了很多困難，像是如果想要讓這套系統連接 MySQL，我們需要對 MySQL 做版本控制，App Inventor 有支援的 MySQL 版本並不多，我花了很多時間在調整。另外由於這算是我第一次製作軟體相關的專案，在製作時遇到的很多問題我第一時間無法解決，例如：框架的不同、套件的不熟悉等。那由於 APP Inventor是一個很基礎的工具，在開發時可能影很多不足的地方，那我的解決方法是去 APP Inventor 的官網討論串去尋找別人製作的套件，像是上傳影片的功能在 APP Inventor 裡是做不出來的，所以我們使用了別人製作的套件。\n比賽心得這個比賽對我來說算是第一次入坑 APP 製作，雖然 APP Inventor 是一款積木的編輯網站，但這並不妨礙我學習邏輯相關的知識，我也在這次比賽中融入了我很熟悉的 MySQL。軟體跟網站使用的體驗真的很不同，像是這種給年長者使用的軟體越簡潔越好，使用APP可以減少長者學習使用連覽器的時間。未來我還會繼續開發APP相關的專案。\n","tags":["比賽","社會議題","軟體","創作"]},{"title":"田野調查-IxDA","url":"/RayBlog/2024/09/01/%E7%94%B0%E9%87%8E%E8%AA%BF%E6%9F%A5-IxDA/","content":"田野調查-IxDA\n    校定必修課\n\n\n📋 前言參與 IxDA 田野計畫的過程，從事前規劃到實際參與，探討 IxDA 如何發想專案主題，以及如何將這些方法應用於實際的提案競賽中。\n\n\n田野內容參與 IxDA 田野計畫的過程，從事前規劃到實際參與，探討 IxDA 如何發想專案主題，以及如何將這些方法應用於實際的提案競賽中。\n\n田野計劃我們將利用自主學習時間進行田野調查，目標時數位18小時到22小時，我們將跟隨IxDA的理事長一同進行IxDA舉辦的活動。田野時數被分為四次，我們將進行一次訪案、兩次的線上發想討論、一次的實體工作坊以及最後的復盤訪談。\n田野行動（ㄧ）我們邀請 IxDA 的理事長來到我們數位實驗高中的吉林基地做訪談，那我們主要針對提案發想的方式以及工具做訪談，我們討論到的發想工具包含曼陀羅發想法、利害關西人圓餅圖等。那我們也著重詢問了理事長關於 AI 運用相關的問題，那對此理事長保持者樂觀的想法，她說：如果 AI 可以幫助我們發想到生活中的問題甚至是解決這個問題，那有什麼不好，重點在於使用 AI 後有沒有產出。\n那在這一次的田野中我主要的反思在於 AI 的使用，我在想如果使用 AI 來製作利害關西人圓餅圖感覺會有很好的效果。那我會在下一次的田野線上討論中使用。\n\n田野行動（二）這次的討論我們選擇線上的原因是因為IxDA發派給我們得組別來自復興高中一年級，我們採取線上 meet 的方式比較方便。我在討論一開始先請復興高中的學生自我介紹，我自己也有自我介紹，這樣做的原因是讓我快速認識他們，他們也可以快速認識我。\n那我們開始討論後，我使用 IxDA 提供給我們的曼陀倫發想法進行我們的發想，這個發想法的使用方式是將我們關注的一台例如：SDGs，放在中間，然後將它的子項目，例如SDGs5.1，放在紅色周圍的 8 個方格內，然後在將這八個方格丟出去變成最外圍的 8 個曼陀羅，最後將這個議題的解決方法或參考資料填在最外圈的曼陀羅裡。那在這裡我是不希望他們使用 AI 的，但我們在下方的圖片中可以很明顯看到 AI 的痕跡，不過如果能產出結果這也不一定是件壞事。那這一部分結束後我們使用 IxDA 提供的利害關西人圖來進行發想，這一步主要是為了確定我們的目標族群。在這個部分我開放使用 AI，效果出奇的不錯，這個發想法的使用方式就是將與這個議題最相關的人擺中間，最不相關的人擺外圈。\n那我們田野行動二到這邊就結束了，總共 4 個小時的討論時間。\n\n\n田野行動（三）第三次的田野我們跟隨 IxDA 以及我們在 IxDA 認識的夥伴們來到了青年舉證提案競賽的工作坊，或者我們可以稱它為青年舉證提案競賽的選拔賽。那我在這個工作坊裡學習到了如：規劃、展示、推銷等技巧。我想分享我印象最深刻的“規劃”的部分，講師說我們在歸回前、規劃中時都會有懼怕、不確定、懷疑等想法，而我們以 30 小時的 MVP(Minimum Viable Product) 為單位，當我們做了 60 個小時以上都做不出一套基本的 MPV 時我們就應該放棄了，這代表我的能力還沒辦法支持我做出這個產品，那經過我跟理事長的討論，我將 60 個小時縮減成 30 個小時，對於目前處於高中生階段的我來說，如果 30 個小時還做不出東西的話那放棄才是最好的選擇(因為高中只有3年)。\n一間公司在行銷產品的時候最重要的是吸引消費者的注意力，講師舉了一套廣告公式：注意力→說服力→可行性，舉例：我能控制太陽(注意力)，利用 200 顆低軌衛星(說服力)，太空實驗證明(可行性)。依照這一套公式，行銷成功的機率會大幅提升。\n我前面有提套這個活動是個工作坊也是個選拔賽，那很可惜我們沒有入選，那我覺得下一次我們更有經驗後我們可以做的更好，那因為這次的主題是田野調查 IxDA，所以我就不花太多的篇幅在比賽的部分。\n\n\n田野行動（四）第四次田野調查也是最後一次田野調查，我們邀請理事長一同吃飯並進行最後的復盤訪談，我們將依據這次青年舉證提案競賽未入選的原因進行討論，除此之外我們還將進一步了解 IxDA。\n我們這一組提出了「大眾運輸工具等候人數顯示系統」的提案。這個系統主要有兩個功能：首先，司機可以透過系統了解下一站的等候人數，讓載客量更具彈性，避免運量浪費；其次，系統能提醒司機下一站是否需要停車，減少因未看見乘客舉手而產生的衝突。對乘客而言，他們也能透過系統查看各站點的等候人數，規劃更合適的路線。\n在與理事長討論未入選原因時，他指出這個主題其實並不新穎。包括 IxDA 內部過去也有類似的提案，但受限於技術成熟度，大數據分析和網路資訊整合一直是個難題。政府難以整合如此龐大的系統，私人企業也無法完全掌控客運系統，使得這個想法遲遲未能實現。不過，理事長也提到，隨著 AI 和 IOT 技術的進步，這樣的提案或許在不久的將來就能實現。\n在後續與理事長的深入訪談中，我們更全面地了解了 IxDA 作為互動設計協會的角色。協會透過多元的方式影響社會，主要是通過舉辦各類活動，有效地串連企業人才和資源。他們建立的會員制度不僅提供福利，更重要的是培養了真誠的社群連結，進而吸引優秀人才投入志工行列，促成大型會議的成功舉辦。\nIxDA持續關注產業最新趨勢，並以此為基礎策劃活動內容。儘管在過程中偶爾會遇到講師不符預期等挑戰，但仍成功為參與者創造了寶貴的職業發展機會。許多會員透過活動建立的人脈網絡，找到了新的工作或合作夥伴。值得一提的是，IxDA特別重視與教育機構的合作，例如與北科大互動設計系連續七年合作舉辦工作坊，成功幫助學生在進入職場前，獲得完整的設計思考實務經驗。\n個人反思與未來展望這次的提案競賽我採用了專業的發想工具，這讓我的發想過程變得更有邏輯，在書寫提案計劃書的時候也顯得更有說服力，以前我無法像這樣有系統性的發想，都是依靠突然的靈感來實現創意。\n在行銷上我認為我還有很長的路要走，在這次的青年舉證提案競賽中，我認為我沒有將我這套「大眾運輸工具等候人數顯示系統」推銷好，我沒有在一開始就抓住評審的興趣，以至於評審一直很想反駁我的觀點，我可能需要準備更長的時間。但經過跟理事長的討論，也有可能這個提案已經有很多人提過類似的了，所以評審不敢興趣\n在未來我會注重在數位實驗高中內的提案，因為我們學校是剛創立三年的新學校，有很多東西是可以透過設計思考改變的，我將努力做到這件事\n","tags":["社會議題","公民行動","田野調查"]},{"title":"第九屆海峽兩岸青少年創客大賽","url":"/RayBlog/2024/07/09/%E7%AC%AC%E4%B9%9D%E5%B1%86%E6%B5%B7%E5%B3%BD%E5%85%A9%E5%B2%B8%E9%9D%92%E5%B0%91%E5%B9%B4%E5%89%B5%E5%AE%A2%E5%A4%A7%E8%B3%BD/","content":"第九屆海峽兩岸青少年創客大賽\n    榮獲優勝\n\n\n📋 前言這個比賽是類似 IEYI 發明展，不同的地方是他要現場做出來。我們這組做的東西是智能電梯，這個電梯的功能是透過影像辨識來偵測電梯內的人數。如果電梯客滿那就不會會應電梯外的請求指令，電梯會優先將電梯艙內的請求完成才會回應電梯外的搭乘請求。\n\n關於比賽自2015年時任海協會會長陳德銘考察Fablab臺北及同濟大學設計創意學院並提出創辦構想後，海峽兩岸青少年創客大賽正式啟動。首屆比賽於2016年舉行，截至2023年，已成功舉辦八屆，吸引了超過3300名青少年參與。\n海峽兩岸青少年創客大賽自2016年首辦以來，這項賽事由海峽兩岸關係協會指導，上海市台辦、同濟大學聯合主辦，同濟大學設計創意學院承辦，旨在通過創客活動促進青少年的交流與互動。\n比賽以「眾智未來」為核心主題，鼓勵參賽者以SDGs為導向，秉持世界公民的視野，關注社會、經濟與環境挑戰。參賽者結合創新設計理念與前沿科技，致力於創造兼具社會價值與產業潛力的作品，展現青年在創意與技術領域的卓越能力\n\n發想過程這是一次創客大賽，那我們思來想去還是想不到要做什麼，那這時候我在一段Apple CEO Tim Cook的採訪中聽到這麼一段話，他說：所有的靈感都來自於生活中的”痛點“，人們因為習慣了這些痛點所以沒有去改變，而作為創作者作為科技屆的標竿，蘋果有義務解決這些痛點。這句話讓我開始思考我生活中有什麼痛點，最後真的讓我想到了，我們數位實驗高中的學習基地在四樓和五樓，每天上下課都會有很多人，那電梯在五樓的時候就客滿了，但是電梯還是在四樓就停下來，這如果是在這種六層樓的建築物那可能還好，如果是在那種30層樓的高樓裡，這些等待電梯開關門時間就被浪費了，不只體驗很差，如果我剛好要趕公車，心情就會很煩燥。所以這是我們想要解決的“痛點”。\n準備過程這次的創客大賽規定要我們現場做出來，所以這邊的準備過程是先在學校做一次，現場才不會顯得很慌張。我們用Onshape 畫出電梯的外殼，並用雷射切割幾切出來，那在內部硬體方面，我們採用的方式是使用樹莓派5驅動步進馬達來做出電梯上下移動的效果。那至於我們要怎麼判斷電梯內有沒有客滿，我們決定採用影像辨識的方式，我們本來準備使用 YoLo5 nano 但我們發現會導致電梯客滿的元素不只是”人“，還有可能是輪椅、嬰兒車、推車…等，所以我們改用 OpenCV 的顏色辨識功能，我們將電梯艙的地板塗成紅色，讓 OpenCV 偵測看看有沒有紅色地板，如果偵測到紅色地板，代表電梯沒有客滿，如果沒有偵測到紅色地板，代表電梯客滿了。那以上就是我們整個作品的詳細功能以及製作方式。\n\n決賽環節我們 7&#x2F;11 去到上海，第一天我們就深感不秒，我們住的那間酒店的電梯就有相關的功能，在我們搭電梯下樓的時候，我們發現當電梯滿載的時候，電梯是不會停其他樓層的，電梯外的顯示器上會寫該電梯滿載中。那因為距離比賽還有一天半，我們緊急討論 PlanB，最後我們決定增加一個緊急醫療功能，這個功能是在電梯艙內增加一顆按鈕，當有人在高樓層昏倒需要送醫的時候，患者的家屬可以將患者抬進電梯並按下該按鈕，這時候電梯會忽視其他樓層的請求，直接將患者送到一樓，這樣可以減少患者的送醫時間，增加患者的存活率。\n7&#x2F;12 下午是熟悉環境，這時候我們又得之了一個壞消息，樹莓派只有4台，所以我們又馬上坐下來商討 PlanC，我們想既然樹莓派等於是一台效能低的電腦，那我們手上不就有一台效能高的電腦嗎，所以我們的 PlanC 就是，當我們沒有搶到樹莓派時我們就在電腦使用 Pyserial 來跟 Arduino 通訊，然後 OpenCV 也直接在電腦上運作。\n7&#x2F;13 開幕式後就開始比賽了，比到 7&#x2F;14 中午 12 點。比賽開始後我們果然沒有搶到樹莓派，所以我們直接採用 PlanC，那過程中可以說很不順利，由於昨天臨時計劃使用筆電當作主機，所以昨天在酒店臨時寫了程式碼，但到了比賽現場出現了很多 BUG 那我們的時間幾乎都在 deBUG。我們最後還是有把作品做出來，只是有很多 BUG，我們決定用演的，我設定了一個程序，只要照這這個程序走就不會錯。那到了評審環節，我們做的非常失敗，因為現場非常的吵，我的夥伴又有點生病，聲音發不出來，導致評審其實沒有聽到我們說什麼，雖然我們有把醫療功能演示出來，但我們沒有成功抓住評審的注意力，以至於我們最後只獲得優勝。那對於這樣的結果我只能說有點不甘心，因為我覺得我們的想法非常好，但因為我的表達能力沒有那麼好，導致我認為的好想法沒有受到關注。\n\n比賽心得雖然我們的作品沒有受到評審的青睞，但我覺得我還是收穫很多，我發現我對於“隨機應變”這個技能還掌握的不夠好，後來想想，其實我們靜下心來，將作品的外觀做好做漂亮然後再做一份漂亮的簡報介紹，這樣做的結果或許會比我在那邊鑽研一些小功能小 bug 來的划算，但我覺得這就是經驗，如果下次還有機會參加類似的比賽，我也許可以做得更好。未來我將帶這這個作品征戰 IEYI 發明展。\n","tags":["比賽","創客","國際交流"]},{"title":"資訊安全密室逃脫","url":"/RayBlog/2024/03/25/%E8%B3%87%E8%A8%8A%E5%AE%89%E5%85%A8%E5%AF%86%E5%AE%A4%E9%80%83%E8%84%AB/","content":"資訊安全密室逃脫\n    團體專案\n\n\n\n.image-gallery {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 10px;\n  justify-content: center;\n  margin: 20px 0;\n}\n.image-gallery img {\n  width: 200px;\n  height: 150px;\n  object-fit: cover;\n  border-radius: 8px;\n  box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n}\n@media (max-width: 768px) {\n  .image-gallery img {\n    width: 45%;\n    height: 120px;\n  }\n}\n@media (max-width: 480px) {\n  .image-gallery img {\n    width: 100%;\n    height: 200px;\n  }\n}\n\n\n📋 前言第二屆的第一次科技進階課以資安相關內容為主。在我們數位實驗高中，每年冬天都有舉辦學習分享會的傳統，每堂課都會準備展覽內容。課程討論時，我想到可以結合資安與創客元素設計一個密室逃脫。經過與老師討論，我們決定這學期的學習分享會將以密室逃脫作為展覽主題。\n\n\n企劃起源第二屆的第一次科技進階課以資安相關內容為主。在我們數位實驗高中，每年冬天都有舉辦學習分享會的傳統，每堂課都會準備展覽內容。課程討論時，我想到可以結合資安與創客元素設計一個密室逃脫。經過與老師討論，我們決定這學期的學習分享會將以密室逃脫作為展覽主題。\n規劃過程在確定密室逃脫的主題故事之前，我們決定先體驗一次解謎式的密室逃脫。我們選擇了一款名為「消失的實驗室」的密室逃脫進行體驗。過程中，我們不僅深入思考如何設計謎題，還探討了故事與謎題的結合方式，為後續創作提供靈感。\n我們最後的規劃是這樣：討論逃脫主題(必須跟資安相關)、分工、製作解謎道具、布置逃脫空間。\n最後我們的主題是：消失的時間機器之資安密室逃脫。\n分工我的工作主要聚焦在故事組的道具卡牌、劇情梳理、與資安的連結、布景，以及道具組的web架設、IOT的連接。最主要是當故事組與道具組之間溝通的橋樑。\n\n遇到的困難我們故事組遇到的困難主要是不知道怎麼相謎題融入到故事中，我們的故事跟謎題完全是分離的，那經過老師的修正以及ChatGPT的幫助，我們終於完成劇本以及道具文件。\n那對於我來說我還遇到了另一個困難，在跟謎題組的溝通中我們發現道具組無法玩全滿足我們故事組的要求，那因為我不是道具組的組員，所以我無法準確的知道他們的進度，於是我在故事組的部分完善後加入了道具組，這樣可以直接製作故事裡需要的道具以及可以更方便的跟道具組溝通。我在道具組主要負責樹莓派跟所有道具的連接，像是故事組設計了一把金鑰，插下這把金鑰後時間機器才能夠啟動，那麼道具組就要把它做出來，但他們來不及做出來，所以我拿過來自己做，我利用樹莓派裡得Python判斷金鑰的序號，如果金鑰的號碼正確那就啟讓所有的燈條亮起來。那這個部分做完後整個密室逃脫的就做完了。\n作品成果學習分享會兩天的時間我們總共了接待20組，那我們也利用空閒的時間改進我們在接待時發現的問題，例如：玩家在閱讀故事文件時很難發現其中的提示，於是我們把提示改的明顯一點，那我們也有聽到反饋說這個密室逃脫一點都不恐怖，於是我們將冷氣調低到19度並播放恐怖音樂，那麼以下照片就是我們在接待時所拍攝的\n\n\n\n\n\n\n\n\n策展逐字稿開場前情提要：歡迎大家來玩科技進階密室逃脫，在這次的遊戲中你們扮演的是一群失憶的科學家收到神秘郵件來到這裡，我作為NPC在這裡能給的提示是：請詳細閱讀每一分文件以及越不合理的解法有可能就是正解\n遊戲後解說：在第一關我們想要表達的是密碼不應該直接貼在螢幕上，即便他已經是加密過的摩斯密碼但仍然不應該這樣紀錄，另外如果有網頁或資安相關專業的應該會下意識打開F12查HTML，這時候你就會發現這個網頁的密碼驗證是寫在前端，那這在製作網站時也是不應該出現的寫法。我們破解網頁後就可以發現這邊有一份文件，那這個文件裡有寫說：「保險箱的密碼好像是文件日期」，而我們查看文件日期是2&#x2F;13，那麼我們在根據附圖的小地圖就可以發現保險箱的存在，將保險箱的密碼轉到213就可以破解。那像這樣將密碼保存在電子郵件的方式是不恰當的，很容易被發現。那我們閱讀第二關中的文件可以發現，裡面寫說：「某次大停電保險箱突然打開，不知道有沒有被修復」，那這段文字是想要讓玩家嘗試將電源拔掉，在資訊安全中，駭客可能會透過讓伺服器斷電在重啟的方式竊取資料。那打開保險箱後我們可以發現密碼盤的線是完全沒有接東西的。透過第三關的文件我們可以了解到許多科學家的指紋都被竊取下來了，而這些指紋就散落在保險箱附近，那我們從中找出跟保險箱上指紋相同的磁扣放上去後就能打開保險箱。那這個關卡主要是想要傳達不要將指紋上傳到網路上，會有很多個資上的問題。在第四關的文件中我們了解到有一個工程師設計了一個電流急急棒保險箱，但鐵絲跟電線的地方似乎沒接好，那這句話其實是希望各位將保險箱上的電線和鐵絲分離，然後將鐵絲直接套到終點然後再接電，這樣就可以直接將保險箱打開。那透過第五關的文件我們可以發現我們已經來到最終關卡了，文件寫說修復時間機器的方法就是將所有零件組裝上並插上正確的鑰匙，那我們透過接線圖上的提示將線接好後插上正確的鑰匙後時間機器就修好了。以上就是整個密室逃脫的解說，謝謝大家\n\n心得透過這一次特別的非個人專案，我對於分工合作又更熟悉了，在最後的策展中我們刻意弱化了故事的比重，除非有玩家問，否則我們不會刻意去解釋故事在講什麼，這麼做的原因是因為我們想要讓玩家了解更多的資安知識，那我覺得這樣比較符合這門的的主題。其實我們是在策展前一天才做完，當下的我很緊張，那我們也是在這樣到緊張中將密室逃脫做出來了，我覺得這是一次非常特別專案，那未來一定也會有更多類似的專案，總之我很期待。\n\n","tags":["教育","創作","資訊安全","學習分享"]}]